{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StrategicalIT/PipedPiperAI/blob/main/Lab08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6cae130-b662-46d8-9b14-da63c83f8b31",
      "metadata": {
        "id": "a6cae130-b662-46d8-9b14-da63c83f8b31"
      },
      "source": [
        "# LAB 8: Loading and chunking data with LlamaIndex\n",
        "In this lab we are going to see how frameworks like LlamaIndex simplify common workflow tasks. In this particular example we will explore how to ingest documents. This is an example of how these frameworks aim to provide a lot of functionality with a simple interface."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0cf3c1c-1f52-41da-a3a1-15b2ca447f3d",
      "metadata": {
        "id": "c0cf3c1c-1f52-41da-a3a1-15b2ca447f3d"
      },
      "source": [
        "LlamaIndex provides many integrations that have been provided by the community. You can glance at what's available in LlamaHub. At the top you can use the filters to see integrations of only the type you are interested in, for example [data loaders also known as readers](https://llamahub.ai/?tab=readers). You can see how popular they are and when they were last updated."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99ad1ed7-f203-47a9-8f10-12a1e34e5af5",
      "metadata": {
        "id": "99ad1ed7-f203-47a9-8f10-12a1e34e5af5"
      },
      "source": [
        "In this exercise we are going to play with the [simple directory reader](https://docs.llamaindex.ai/en/stable/module_guides/loading/simpledirectoryreader/). As you can see in its documentation page it supports many types of text files including PDF, Word and PowerPoint. It even supports some popular image, audio and video formats. All these files are treated as sources of text and automatically detected by the file extension. As you can image, all these formats are totally different from each other and the process of extracting text from them is different, but \"simpledirectoryreader\" provides a simple interface to extract data from all of them at once."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21d849f9-b68b-4de3-9079-9344b68217fa",
      "metadata": {
        "id": "21d849f9-b68b-4de3-9079-9344b68217fa"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9189748d-cb87-4066-83ed-8843d49e7118",
      "metadata": {
        "id": "9189748d-cb87-4066-83ed-8843d49e7118"
      },
      "source": [
        "The first step is to install the necessary libraries. In this case we will install the core llama-index package as this includes llama-index-core that simpledirectoryreader is part of. Also notice how we are installing docx2txt which is used to extract text from word documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fb3dbdb8-2c89-40b9-a1a5-532401e9ec5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb3dbdb8-2c89-40b9-a1a5-532401e9ec5a",
        "outputId": "2a4c7bec-6c65-4c09-8399-a02a199e142f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.12.47)\n",
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.11/dist-packages (0.9)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.12)\n",
            "Requirement already satisfied: llama-index-cli<0.5,>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.4)\n",
            "Requirement already satisfied: llama-index-core<0.13,>=0.12.47 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.47)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.7.8)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.7)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.6,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.5.1)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.2)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.9)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.93.0)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (3.11.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (2.1.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (2025.3.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (1.0.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.47->llama-index) (2.0.41)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (4.14.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.47->llama-index) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud==0.1.30 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.30)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud==0.1.30->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.6.15)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (4.13.4)\n",
            "Requirement already satisfied: pandas<2.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.2.2)\n",
            "Requirement already satisfied: pypdf<6,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (5.7.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.41)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.47->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.47->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.47->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.47->llama-index) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.47->llama-index) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.47->llama-index) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.47->llama-index) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.47->llama-index) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.47->llama-index) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.47->llama-index) (4.3.8)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.47->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.47->llama-index) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.47->llama-index) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.47->llama-index) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.47->llama-index) (0.2.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.41 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.41)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.47->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.47->llama-index) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.47->llama-index) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.47->llama-index) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.47->llama-index) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.47->llama-index) (3.2.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.47->llama-index) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.47->llama-index) (3.26.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.41->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.47->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (1.17.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.47->llama-index) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.47->llama-index) (3.0.2)\n",
            "Requirement already satisfied: llama-index-llms-nvidia in /usr/local/lib/python3.11/dist-packages (0.3.4)\n",
            "Requirement already satisfied: llama-index-embeddings-nvidia in /usr/local/lib/python3.11/dist-packages (0.3.4)\n",
            "Requirement already satisfied: llama-index-core<0.13,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-nvidia) (0.12.47)\n",
            "Requirement already satisfied: llama-index-llms-openai-like<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-nvidia) (0.4.0)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-nvidia) (0.4.7)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (3.11.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (2.1.3)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (2025.3.2)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (1.0.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (2.0.41)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (4.14.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (1.17.2)\n",
            "Requirement already satisfied: openai<2,>=1.81.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-openai<0.5,>=0.4.0->llama-index-llms-nvidia) (1.93.0)\n",
            "Requirement already satisfied: transformers<5,>=4.37.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-openai-like<0.5,>=0.4.0->llama-index-llms-nvidia) (4.53.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (3.1.6)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (4.3.8)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (0.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (2024.11.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.5,>=0.4.0->llama-index-llms-nvidia) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.5,>=0.4.0->llama-index-llms-nvidia) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.5,>=0.4.0->llama-index-llms-nvidia) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.5,>=0.4.0->llama-index-llms-nvidia) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (3.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.5,>=0.4.0->llama-index-llms-nvidia) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.5,>=0.4.0->llama-index-llms-nvidia) (0.33.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.5,>=0.4.0->llama-index-llms-nvidia) (24.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.5,>=0.4.0->llama-index-llms-nvidia) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.5,>=0.4.0->llama-index-llms-nvidia) (0.5.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (3.26.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers<5,>=4.37.0->llama-index-llms-openai-like<0.5,>=0.4.0->llama-index-llms-nvidia) (1.1.5)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.0->llama-index-llms-nvidia) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index docx2txt\n",
        "!pip install llama-index-llms-nvidia llama-index-embeddings-nvidia"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cac5d6e-0d59-4545-8de2-ff3969a8b3b5",
      "metadata": {
        "id": "1cac5d6e-0d59-4545-8de2-ff3969a8b3b5"
      },
      "source": [
        "First we need to import SimpleDirectoryReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "56f34438-0512-4a19-a340-f977c8964839",
      "metadata": {
        "id": "56f34438-0512-4a19-a340-f977c8964839"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import SimpleDirectoryReader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2545d976-c99f-4a44-a830-b88afbdf4195",
      "metadata": {
        "id": "2545d976-c99f-4a44-a830-b88afbdf4195"
      },
      "source": [
        "For this exercise we have prepared a directory called \"data\" that contains three files: a txt, a pdf and a docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6669b9cb-0331-4ece-9939-cdf6063f2867",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6669b9cb-0331-4ece-9939-cdf6063f2867",
        "outputId": "924c6580-c9fb-49c6-802b-554b1e500e02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 284\n",
            "-rw-r--r-- 1 root root 289932 Jul  7 07:06 poweredge-r760xa-spec-sheet.pdf\n"
          ]
        }
      ],
      "source": [
        "# if using Google Colab, we need the /content prefix\n",
        "!ls -l /content/PipedPiperAIData/\n",
        "# if running a local notebook, then just the directory name is ok e.g. data\n",
        "#!ls -l data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "695791ec-120a-4402-a550-6f23dc46c11a",
      "metadata": {
        "id": "695791ec-120a-4402-a550-6f23dc46c11a"
      },
      "source": [
        "The following line of code is sufficient to load all the data from these documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6ae207cd-f93f-48c5-90ef-ab838e012fe7",
      "metadata": {
        "id": "6ae207cd-f93f-48c5-90ef-ab838e012fe7"
      },
      "outputs": [],
      "source": [
        "documents = SimpleDirectoryReader(\"/content/PipedPiperAIData/\").load_data()\n",
        "# for Google Colab be we probably need the /content prefix and point to a folder we've created at runtime with documents uploaded\n",
        "# for local notebook, probably just point directly to the folder e.g. data assuming the folder is in the same dir as this notebook run from"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5202b6d7-7643-44c1-9227-6ed9a60bb325",
      "metadata": {
        "id": "5202b6d7-7643-44c1-9227-6ed9a60bb325"
      },
      "source": [
        "Now you can simple show the contents of the \"documents\" variable to see that the text from the documents was indeed extacted. Each document in the list contains also the id and a lot of metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "14432aec-a48f-42a3-83e4-470a827950d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14432aec-a48f-42a3-83e4-470a827950d4",
        "outputId": "7a99e246-aa36-462f-f6db-532e44dc1f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   Document(id_='fda5c507-abab-4ddf-94df-48ea2af9e399', embedding=None, metadata={'page_label': '1', 'file_name': 'poweredge-r760xa-spec-sheet.pdf', 'file_path': '/content/PipedPiperAIData/poweredge-r760xa-spec-sheet.pdf', 'file_type': 'application/pdf', 'file_size': 289932, 'creation_date': '2025-07-07', 'last_modified_date': '2025-07-07'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='PowerEdge R760xa\\nHigh performance, scalable server for \\nintensive GPU applications\\nThe Dell PowerEdge R760xa, is a purpose-built server designed to boost acceleration performance across the widest \\nrange of customer needs.\\nInnovate at scale with challenging and emerging workloads\\nMaximize your workload performance and boost outcomes with scale as you grow compute, flexibly supporting a wide range \\nof GPUs in a dual-socket/2U air-cooled server, accelerating applications from AI training and inferencing to Digital Twins to \\nperformance graphics and dense power-user collaboration environments.\\n• Leverage a powerful architecture and the power of two 4th or 5th Generation Intel® Xeon® processors with high core count \\nof up to 64 cores and the latest on-chip innovations to boost AI and ML operations\\n• Up to four double-width PCIe Gen5 accelerators or up to 12 single-width* PCIe accelerators to break through the density \\nboundaries of todays and tomorrow’s computing\\n• Support for PCIe GPU adapters from NVIDIA, AMD, and Intel, delivering superior outcomes with one platform\\nAccelerated I/O throughput\\n• Deploy latest generation technologies including DDR5, Gen4 NVLink, PCIe Gen 5, and E3.S NVMe SSDs to push the \\nboundaries of data flow and computing possibilities.\\n• Scale up your needs supporting up to 32 DDR5 memory DIMM slots, up to eight drives, and PCIe Gen 5 expansion slots\\n• Air-cooled design with front-facing accelerators enables better cooling and supports higher TDP accelerators (up to 400 W) \\nCyber Resilient Architecture for Zero Trust IT environment & operations\\nSecurity is integrated into every phase of the PowerEdge lifecycle, including protected supply chain and factory-to-site integrity \\nassurance. Silicon-based root of trust anchors end-to-end boot resilience while Multi-Factor Authentication (MFA) and role-based \\naccess controls ensure trusted operations.\\nIncrease efficiency and accelerate operations with autonomous collaboration\\nThe Dell OpenManage™ systems management portfolio delivers a secure, efficient, and comprehensive solution for PowerEdge \\nservers. Simplify, automate and centralize one-to-many management with the OpenManage Enterprise console and iDRAC.\\nSustainability\\nFrom recycled materials in our products and packaging, to thoughtful, innovative options for energy efficiency, the PowerEdge \\nportfolio is designed to make, deliver, and recycle products to help reduce the carbon footprint and lower your operation costs. \\nWe even make it easy to retire legacy systems responsibly with Dell Technologies Services.\\nRest easier with Dell Technologies Services\\nMaximize your PowerEdge Servers with comprehensive services ranging from \\nConsulting, to ProDeploy and ProSupport suites, Data Migration and more \\n– available across 170 countries and backed by our 60K+ employees and \\npartners.\\n* Indicates up to 12 Single-width (PCIe x8), and up to 8 Single-width (PCIe x16).\\nSpecification Sheet\\nPowerEdge R760xa\\nThe Dell PowerEdge R760xa is a high-\\nperformance scale -as you grow server \\ndesigned for use cases like\\n• AI/ML/DL Training and Inferencing \\n• Digital Twins, render graphics\\n• Virtualization and VDI graphics\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
            "    Document(id_='4d6c9e03-824b-4a3c-a96b-a2d58fec29d3', embedding=None, metadata={'page_label': '2', 'file_name': 'poweredge-r760xa-spec-sheet.pdf', 'file_path': '/content/PipedPiperAIData/poweredge-r760xa-spec-sheet.pdf', 'file_type': 'application/pdf', 'file_size': 289932, 'creation_date': '2025-07-07', 'last_modified_date': '2025-07-07'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Feature Technical Specifications\\nProcessor Up to two 4th Generation Intel Xeon Scalable processor with up to 56 cores per processor and optional Intel® QuickAssist\\nTechnology\\nUp to two 5th Generation Intel Xeon Scalable processor with up to 64 cores per processor and optional Intel® QuickAssist \\nTechnology  \\nMemory • 32 DDR5 DIMM slot, supports RDIMM 8 TB max\\n• Speeds up to 4800 MT/s on the 4th Generation Intel® Xeon Scalable processor\\n• Speeds up to 5600 MT/s on the 5th Generation Intel® Xeon Scalable processor\\n• Supports registered ECC DDR5 DIMMs only\\nStorage controllers • Internal controllers: PERC H965i, PERC H755, PERC H755N, PERC H355, HBA355i, HBA465i\\n• Internal Boot: Boot Optimized Storage Subsystem (BOSS-N1): HWRAID 2 x M.2 NVMe SSDs, or USB\\n• External HBA (non-RAID): HBA355e, HBA465e, H965e\\n• Software RAID: S160\\nDrive Bays Front bays: \\n• Up to 6 x E3.S Gen5 NVMe, max 46.08 TB\\n• Up to 6 x 2.5-inch NVMe, max 92.16 TB\\n• Up to 8 x 2.5-inch SAS/SATA/NVMe, max 122.88 TB\\nPower Supplies • 3200 W Titanium  277–305 VAC or 336 HVDC, hot swap redundant\\n• 2800 W Titanium 200–240 VAC or 240 HVDC, hot swap redundant\\n• 2400 W Platinum 100–240 VAC or 240 HVDC, hot swap redundant\\nCooling Options • Air cooling\\n• Optional Direct Liquid Cooling (DLC)\\nNote: DLC is a rack solution and requires rack manifolds and a cooling distribution unit (CDU) to operate.\\nFans • Standard (STD) fan\\n• Up to six hot plug fans \\nDimensions • Height – 86.8 mm (3.41 inches)\\n• Width – 482 mm (18.97 inches)\\n• Depth – 946.73 mm (37.27 inches) - without bezel\\n                     932.89 mm (36.73 inches) - with bezel\\nForm Factor 2U rack server\\nEmbedded Management • iDRAC9\\n• iDRAC Direct\\n• iDRAC RESTful API with Redfish\\n• iDRAC Service Module\\n• Quick Sync 2 wireless module\\nBezel Optional LCD bezel or security bezel\\nOpenManage Software • OpenManage Enterprise\\n• OpenManage Power Manager plugin\\n• OpenManage Service plugin\\n• OpenManage Update Manager plugin\\n• CloudIQ for PowerEdge plug in\\n• OpenManage Enterprise Integration for VMware vCenter\\n• OpenManage Integration for Microsoft System Center\\n• OpenManage Integration with Windows Admin Center\\nMobility OpenManage Mobile\\nOpenManage Integrations • BMC Truesight\\n• Microsoft System Center\\n• OpenManage Integration with ServiceNow\\n• Red Hat Ansible Modules\\n• Terraform Providers\\n• VMware vCenter and vRealize Operations Manager\\nSecurity • Cryptographically signed firmware\\n• Data at Rest Encryption (SEDs with local or external \\nkey mgmt)\\n• Secure Boot\\n• Secured Component Verification (Hardware integrity check)\\n• Secure Erase\\n• Silicon Root of Trust\\n• System Lockdown (requires iDRAC9 Enterprise or \\nDatacenter)\\n• TPM 2.0 FIPS, CC-TCG certified, TPM 2.0 China NationZ\\nEmbedded NIC 2 x 1GbE LOM card (optional)\\nNetwork Options 1 x OCP card 3.0 (optional)\\nNOTE: The system allows either LOM card or an OCP card or both to be installed in the system.\\nGPU Options Up to 4 x 400 W DW PCIe x16 GPU cards\\nUp to 12 x 75 W SW PCIe x8 GPU cards\\nPorts Front Ports \\n• 1 x iDRAC Direct (Micro-AB USB) port\\n• 1 x USB 2.0\\n• 1 x VGA\\nRear Ports\\n• 1 x Dedicated iDRAC Ethernet port \\n• 1 x USB 2.0\\n• 1 x USB 3.0\\n• 1 x Serial (optional)\\n• 1 x VGA (optional for Direct Liquid Cooling configuration)\\nInternal Ports\\n• 1 x USB 3.0 (optional)\\nPCIe  Up to twelve PCIe slots (x16 connector)\\n• 4 x16 Rear Full height, Half length + 4 x16 Front Full height, Full length DW\\n• 4 x16 Rear Full height, Half length + 8 x 8 Front Full height, Full length SW\\nOperating System and Hypervisors • Canonical Ubuntu Server LTS\\n• Microsoft Windows Server with Hyper-V\\n• Red Hat Enterprise Linux\\n• SUSE Linux Enterprise Server\\n• VMware ESXi\\nFor specifications and interoperability details, see Dell.com/OSsupport.\\nOEM-ready version available From bezel to BIOS to packaging, your servers can look and feel as if they were designed and built by you. For more information, \\nvisit Dell.com -> Solutions -> OEM Solutions..', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
            "    Document(id_='beb8b3b9-189c-4dc6-92f2-6f4cf171cfbd', embedding=None, metadata={'page_label': '3', 'file_name': 'poweredge-r760xa-spec-sheet.pdf', 'file_path': '/content/PipedPiperAIData/poweredge-r760xa-spec-sheet.pdf', 'file_type': 'application/pdf', 'file_size': 289932, 'creation_date': '2025-07-07', 'last_modified_date': '2025-07-07'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Learn more about our \\nsystems management \\nsolutions\\nContact a Dell \\nTechnologies Expert \\nfor Sales or Support\\nSearch our \\nResource Library\\nFollow PowerEdge \\nservers on Twitter\\nLearn more about our \\nPowerEdge servers]\\nDiscover more about PowerEdge servers\\nAPEX on Demand\\nAPEX Flex on Demand Acquire the technology you need to support your changing business with  \\npayments that scale to match actual usage. For more information, visit  \\nwww.delltechnologies.com/en-us/payment-solutions/flexible-consumption/flex-on-demand.htm.\\nCopyright © 2024 Dell Inc. or its subsidiaries.  All Rights Reserved.  Dell Technologies, Dell, and other trademarks are \\ntrademarks of Dell Inc. or its subsidiaries.  Other trademarks may be trademarks of their respective owners.  \\n \\nJuly 2024\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(documents, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2978257a-c306-4543-b7b2-a522f7fd4465",
      "metadata": {
        "id": "2978257a-c306-4543-b7b2-a522f7fd4465"
      },
      "source": [
        "Feel free to experiment with other supported file types by uploading your own files. You can upload your own files using the main Jupyter interface from where you launch the notebooks.\n",
        "\n",
        "As you can see in [the documentation](https://docs.llamaindex.ai/en/stable/module_guides/loading/simpledirectoryreader/), this reader offers many other possibilities like:\n",
        "- reading subdirectories with \"recursive=True\"\n",
        "- include or exclude specific paths and file extensions\n",
        "- limit the amount of files to be ingested\n",
        "It can also traverse remote file systems such as S3, Google drive, SFTP ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de6835d6-9151-4bc5-88f9-56f7adcb1a1e",
      "metadata": {
        "id": "de6835d6-9151-4bc5-88f9-56f7adcb1a1e"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9754015a-977e-4cf9-8fc0-e7f60af7b7fc",
      "metadata": {
        "id": "9754015a-977e-4cf9-8fc0-e7f60af7b7fc"
      },
      "source": [
        "## Chunking"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46460e99-6a0d-4ef1-8505-9f312b9633ef",
      "metadata": {
        "id": "46460e99-6a0d-4ef1-8505-9f312b9633ef"
      },
      "source": [
        "Chunking involves breaking down large data into smaller segments or \"chunks\". This makes the AI solution more efficient, particularly in tasks like semantic search and information retrieval. Chunking helps optimize memory usage, speeds up processing, and improves scalability.\n",
        "\n",
        "This is still an area of active research and it can be done in many ways. You can [check out the LlamaIndex documentation to see what methods are available](https://docs.llamaindex.ai/en/stable/module_guides/loading/node_parsers/modules/). Data scientist need to test what method is the best match for their use case"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b315891d-50e7-41ab-afa1-9e31bca33f8b",
      "metadata": {
        "id": "b315891d-50e7-41ab-afa1-9e31bca33f8b"
      },
      "source": [
        "### Fixed-sized chunking"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4431fcd4-157b-4e9a-b2e7-479a597c5897",
      "metadata": {
        "id": "4431fcd4-157b-4e9a-b2e7-479a597c5897"
      },
      "source": [
        "This is the most basic method and it is based on a fixed amount of tokens. As you can see in the Splitter definition below we can specify how many tokens we want to target per chunk and how many tokens we want to overlap between chunks. This overlap is done to prevent information loss at chunk boundaries to ensure context preservation. This method is the often used for speed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6511fd79-d41a-4f1d-8239-9a1b83d8a664",
      "metadata": {
        "id": "6511fd79-d41a-4f1d-8239-9a1b83d8a664"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.node_parser import TokenTextSplitter\n",
        "\n",
        "splitter = TokenTextSplitter(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=20,\n",
        "    separator=\" \",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2665361a-79b8-4d7e-8c6c-1f74c5fbdd31",
      "metadata": {
        "id": "2665361a-79b8-4d7e-8c6c-1f74c5fbdd31"
      },
      "source": [
        "Now we can show the chunks that were created. Notice the word count is different from 300, because the relationship between words and tokens is not 1-2-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "57a94ab8-e7f2-43c9-818c-3a734263833d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57a94ab8-e7f2-43c9-818c-3a734263833d",
        "outputId": "89421785-a87d-443f-e3fc-5d07bc70e771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== chunk #0, word count:192 ===\n",
            "PowerEdge R760xa\n",
            "High performance, scalable server for \n",
            "intensive GPU applications\n",
            "The Dell PowerEdge R760xa, is a purpose-built server designed to boost acceleration performance across the widest \n",
            "range of customer needs.\n",
            "Innovate at scale with challenging and emerging workloads\n",
            "Maximize your workload performance and boost outcomes with scale as you grow compute, flexibly supporting a wide range \n",
            "of GPUs in a dual-socket/2U air-cooled server, accelerating applications from AI training and inferencing to Digital Twins to \n",
            "performance graphics and dense power-user collaboration environments.\n",
            "• Leverage a powerful architecture and the power of two 4th or 5th Generation Intel® Xeon® processors with high core count \n",
            "of up to 64 cores and the latest on-chip innovations to boost AI and ML operations\n",
            "• Up to four double-width PCIe Gen5 accelerators or up to 12 single-width* PCIe accelerators to break through the density \n",
            "boundaries of todays and tomorrow’s computing\n",
            "• Support for PCIe GPU adapters from NVIDIA, AMD, and Intel, delivering superior outcomes with one platform\n",
            "Accelerated I/O throughput\n",
            "• Deploy latest generation technologies including DDR5, Gen4 NVLink, PCIe Gen 5, and E3.S NVMe SSDs to push the \n",
            "boundaries of data flow and computing possibilities.\n",
            "• Scale\n",
            "\n",
            "\n",
            "=== chunk #1, word count:197 ===\n",
            "NVMe SSDs to push the \n",
            "boundaries of data flow and computing possibilities.\n",
            "• Scale up your needs supporting up to 32 DDR5 memory DIMM slots, up to eight drives, and PCIe Gen 5 expansion slots\n",
            "• Air-cooled design with front-facing accelerators enables better cooling and supports higher TDP accelerators (up to 400 W) \n",
            "Cyber Resilient Architecture for Zero Trust IT environment & operations\n",
            "Security is integrated into every phase of the PowerEdge lifecycle, including protected supply chain and factory-to-site integrity \n",
            "assurance. Silicon-based root of trust anchors end-to-end boot resilience while Multi-Factor Authentication (MFA) and role-based \n",
            "access controls ensure trusted operations.\n",
            "Increase efficiency and accelerate operations with autonomous collaboration\n",
            "The Dell OpenManage™ systems management portfolio delivers a secure, efficient, and comprehensive solution for PowerEdge \n",
            "servers. Simplify, automate and centralize one-to-many management with the OpenManage Enterprise console and iDRAC.\n",
            "Sustainability\n",
            "From recycled materials in our products and packaging, to thoughtful, innovative options for energy efficiency, the PowerEdge \n",
            "portfolio is designed to make, deliver, and recycle products to help reduce the carbon footprint and lower your operation costs. \n",
            "We even make it easy to retire legacy systems responsibly with Dell Technologies Services.\n",
            "Rest easier with Dell Technologies Services\n",
            "Maximize your\n",
            "\n",
            "\n",
            "=== chunk #2, word count:99 ===\n",
            "to retire legacy systems responsibly with Dell Technologies Services.\n",
            "Rest easier with Dell Technologies Services\n",
            "Maximize your PowerEdge Servers with comprehensive services ranging from \n",
            "Consulting, to ProDeploy and ProSupport suites, Data Migration and more \n",
            "– available across 170 countries and backed by our 60K+ employees and \n",
            "partners.\n",
            "* Indicates up to 12 Single-width (PCIe x8), and up to 8 Single-width (PCIe x16).\n",
            "Specification Sheet\n",
            "PowerEdge R760xa\n",
            "The Dell PowerEdge R760xa is a high-\n",
            "performance scale -as you grow server \n",
            "designed for use cases like\n",
            "• AI/ML/DL Training and Inferencing \n",
            "• Digital Twins, render graphics\n",
            "• Virtualization and VDI graphics\n",
            "\n",
            "\n",
            "=== chunk #3, word count:147 ===\n",
            "Feature Technical Specifications\n",
            "Processor Up to two 4th Generation Intel Xeon Scalable processor with up to 56 cores per processor and optional Intel® QuickAssist\n",
            "Technology\n",
            "Up to two 5th Generation Intel Xeon Scalable processor with up to 64 cores per processor and optional Intel® QuickAssist \n",
            "Technology  \n",
            "Memory • 32 DDR5 DIMM slot, supports RDIMM 8 TB max\n",
            "• Speeds up to 4800 MT/s on the 4th Generation Intel® Xeon Scalable processor\n",
            "• Speeds up to 5600 MT/s on the 5th Generation Intel® Xeon Scalable processor\n",
            "• Supports registered ECC DDR5 DIMMs only\n",
            "Storage controllers • Internal controllers: PERC H965i, PERC H755, PERC H755N, PERC H355, HBA355i, HBA465i\n",
            "• Internal Boot: Boot Optimized Storage Subsystem (BOSS-N1): HWRAID 2 x M.2 NVMe SSDs, or USB\n",
            "• External HBA (non-RAID): HBA355e, HBA465e, H965e\n",
            "• Software RAID: S160\n",
            "Drive Bays Front bays: \n",
            "• Up to 6 x E3.S Gen5 NVMe, max\n",
            "\n",
            "\n",
            "=== chunk #4, word count:140 ===\n",
            "Front bays: \n",
            "• Up to 6 x E3.S Gen5 NVMe, max 46.08 TB\n",
            "• Up to 6 x 2.5-inch NVMe, max 92.16 TB\n",
            "• Up to 8 x 2.5-inch SAS/SATA/NVMe, max 122.88 TB\n",
            "Power Supplies • 3200 W Titanium  277–305 VAC or 336 HVDC, hot swap redundant\n",
            "• 2800 W Titanium 200–240 VAC or 240 HVDC, hot swap redundant\n",
            "• 2400 W Platinum 100–240 VAC or 240 HVDC, hot swap redundant\n",
            "Cooling Options • Air cooling\n",
            "• Optional Direct Liquid Cooling (DLC)\n",
            "Note: DLC is a rack solution and requires rack manifolds and a cooling distribution unit (CDU) to operate.\n",
            "Fans • Standard (STD) fan\n",
            "• Up to six hot plug fans \n",
            "Dimensions • Height – 86.8 mm (3.41 inches)\n",
            "• Width – 482 mm (18.97 inches)\n",
            "• Depth – 946.73 mm (37.27 inches) - without bezel\n",
            "                     932.89 mm (36.73\n",
            "\n",
            "\n",
            "=== chunk #5, word count:165 ===\n",
            "932.89 mm (36.73 inches) - with bezel\n",
            "Form Factor 2U rack server\n",
            "Embedded Management • iDRAC9\n",
            "• iDRAC Direct\n",
            "• iDRAC RESTful API with Redfish\n",
            "• iDRAC Service Module\n",
            "• Quick Sync 2 wireless module\n",
            "Bezel Optional LCD bezel or security bezel\n",
            "OpenManage Software • OpenManage Enterprise\n",
            "• OpenManage Power Manager plugin\n",
            "• OpenManage Service plugin\n",
            "• OpenManage Update Manager plugin\n",
            "• CloudIQ for PowerEdge plug in\n",
            "• OpenManage Enterprise Integration for VMware vCenter\n",
            "• OpenManage Integration for Microsoft System Center\n",
            "• OpenManage Integration with Windows Admin Center\n",
            "Mobility OpenManage Mobile\n",
            "OpenManage Integrations • BMC Truesight\n",
            "• Microsoft System Center\n",
            "• OpenManage Integration with ServiceNow\n",
            "• Red Hat Ansible Modules\n",
            "• Terraform Providers\n",
            "• VMware vCenter and vRealize Operations Manager\n",
            "Security • Cryptographically signed firmware\n",
            "• Data at Rest Encryption (SEDs with local or external \n",
            "key mgmt)\n",
            "• Secure Boot\n",
            "• Secured Component Verification (Hardware integrity check)\n",
            "• Secure Erase\n",
            "• Silicon Root of Trust\n",
            "• System Lockdown (requires iDRAC9 Enterprise or \n",
            "Datacenter)\n",
            "• TPM\n",
            "\n",
            "\n",
            "=== chunk #6, word count:166 ===\n",
            "Trust\n",
            "• System Lockdown (requires iDRAC9 Enterprise or \n",
            "Datacenter)\n",
            "• TPM 2.0 FIPS, CC-TCG certified, TPM 2.0 China NationZ\n",
            "Embedded NIC 2 x 1GbE LOM card (optional)\n",
            "Network Options 1 x OCP card 3.0 (optional)\n",
            "NOTE: The system allows either LOM card or an OCP card or both to be installed in the system.\n",
            "GPU Options Up to 4 x 400 W DW PCIe x16 GPU cards\n",
            "Up to 12 x 75 W SW PCIe x8 GPU cards\n",
            "Ports Front Ports \n",
            "• 1 x iDRAC Direct (Micro-AB USB) port\n",
            "• 1 x USB 2.0\n",
            "• 1 x VGA\n",
            "Rear Ports\n",
            "• 1 x Dedicated iDRAC Ethernet port \n",
            "• 1 x USB 2.0\n",
            "• 1 x USB 3.0\n",
            "• 1 x Serial (optional)\n",
            "• 1 x VGA (optional for Direct Liquid Cooling configuration)\n",
            "Internal Ports\n",
            "• 1 x USB 3.0 (optional)\n",
            "PCIe  Up to twelve PCIe slots (x16 connector)\n",
            "• 4 x16 Rear Full height, Half length + 4 x16 Front Full height, Full length DW\n",
            "•\n",
            "\n",
            "\n",
            "=== chunk #7, word count:101 ===\n",
            "Rear Full height, Half length + 4 x16 Front Full height, Full length DW\n",
            "• 4 x16 Rear Full height, Half length + 8 x 8 Front Full height, Full length SW\n",
            "Operating System and Hypervisors • Canonical Ubuntu Server LTS\n",
            "• Microsoft Windows Server with Hyper-V\n",
            "• Red Hat Enterprise Linux\n",
            "• SUSE Linux Enterprise Server\n",
            "• VMware ESXi\n",
            "For specifications and interoperability details, see Dell.com/OSsupport.\n",
            "OEM-ready version available From bezel to BIOS to packaging, your servers can look and feel as if they were designed and built by you. For more information, \n",
            "visit Dell.com -> Solutions -> OEM Solutions..\n",
            "\n",
            "\n",
            "=== chunk #8, word count:102 ===\n",
            "Learn more about our \n",
            "systems management \n",
            "solutions\n",
            "Contact a Dell \n",
            "Technologies Expert \n",
            "for Sales or Support\n",
            "Search our \n",
            "Resource Library\n",
            "Follow PowerEdge \n",
            "servers on Twitter\n",
            "Learn more about our \n",
            "PowerEdge servers]\n",
            "Discover more about PowerEdge servers\n",
            "APEX on Demand\n",
            "APEX Flex on Demand Acquire the technology you need to support your changing business with  \n",
            "payments that scale to match actual usage. For more information, visit  \n",
            "www.delltechnologies.com/en-us/payment-solutions/flexible-consumption/flex-on-demand.htm.\n",
            "Copyright © 2024 Dell Inc. or its subsidiaries.  All Rights Reserved.  Dell Technologies, Dell, and other trademarks are \n",
            "trademarks of Dell Inc. or its subsidiaries.  Other trademarks may be trademarks of their respective owners.  \n",
            " \n",
            "July 2024\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nodes = splitter.get_nodes_from_documents(documents)\n",
        "for i, _ in enumerate(nodes):\n",
        "    print(f\"=== chunk #{i}, word count:{len(nodes[i].text.split())} ===\")\n",
        "    print(nodes[i].text)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54bc8192-2b8c-497b-b15c-a3d6618648af",
      "metadata": {
        "id": "54bc8192-2b8c-497b-b15c-a3d6618648af"
      },
      "source": [
        "### Recursive chunking"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfb6ba94-2137-4bef-be9d-558ec7edb3fe",
      "metadata": {
        "id": "dfb6ba94-2137-4bef-be9d-558ec7edb3fe"
      },
      "source": [
        "Here we use SentenceSplitter. This attempts to split text while respecting the boundaries of paragraphs and sentences. You can compare the results with the previous chunking method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4149e183-85b9-4a64-99b7-5b20f92fcc48",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4149e183-85b9-4a64-99b7-5b20f92fcc48",
        "outputId": "5d004af7-732d-4062-a7f2-2f8a5467265c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== chunk #0, word count:190 ===\n",
            "PowerEdge R760xa\n",
            "High performance, scalable server for \n",
            "intensive GPU applications\n",
            "The Dell PowerEdge R760xa, is a purpose-built server designed to boost acceleration performance across the widest \n",
            "range of customer needs.\n",
            "Innovate at scale with challenging and emerging workloads\n",
            "Maximize your workload performance and boost outcomes with scale as you grow compute, flexibly supporting a wide range \n",
            "of GPUs in a dual-socket/2U air-cooled server, accelerating applications from AI training and inferencing to Digital Twins to \n",
            "performance graphics and dense power-user collaboration environments.\n",
            "• Leverage a powerful architecture and the power of two 4th or 5th Generation Intel® Xeon® processors with high core count \n",
            "of up to 64 cores and the latest on-chip innovations to boost AI and ML operations\n",
            "• Up to four double-width PCIe Gen5 accelerators or up to 12 single-width* PCIe accelerators to break through the density \n",
            "boundaries of todays and tomorrow’s computing\n",
            "• Support for PCIe GPU adapters from NVIDIA, AMD, and Intel, delivering superior outcomes with one platform\n",
            "Accelerated I/O throughput\n",
            "• Deploy latest generation technologies including DDR5, Gen4 NVLink, PCIe Gen 5, and E3.S NVMe SSDs to push the \n",
            "boundaries of data flow and computing possibilities.\n",
            "\n",
            "\n",
            "=== chunk #1, word count:177 ===\n",
            "• Scale up your needs supporting up to 32 DDR5 memory DIMM slots, up to eight drives, and PCIe Gen 5 expansion slots\n",
            "• Air-cooled design with front-facing accelerators enables better cooling and supports higher TDP accelerators (up to 400 W) \n",
            "Cyber Resilient Architecture for Zero Trust IT environment & operations\n",
            "Security is integrated into every phase of the PowerEdge lifecycle, including protected supply chain and factory-to-site integrity \n",
            "assurance. Silicon-based root of trust anchors end-to-end boot resilience while Multi-Factor Authentication (MFA) and role-based \n",
            "access controls ensure trusted operations.\n",
            "Increase efficiency and accelerate operations with autonomous collaboration\n",
            "The Dell OpenManage™ systems management portfolio delivers a secure, efficient, and comprehensive solution for PowerEdge \n",
            "servers. Simplify, automate and centralize one-to-many management with the OpenManage Enterprise console and iDRAC.\n",
            "Sustainability\n",
            "From recycled materials in our products and packaging, to thoughtful, innovative options for energy efficiency, the PowerEdge \n",
            "portfolio is designed to make, deliver, and recycle products to help reduce the carbon footprint and lower your operation costs. \n",
            "We even make it easy to retire legacy systems responsibly with Dell Technologies Services.\n",
            "\n",
            "\n",
            "=== chunk #2, word count:104 ===\n",
            "We even make it easy to retire legacy systems responsibly with Dell Technologies Services.\n",
            "Rest easier with Dell Technologies Services\n",
            "Maximize your PowerEdge Servers with comprehensive services ranging from \n",
            "Consulting, to ProDeploy and ProSupport suites, Data Migration and more \n",
            "– available across 170 countries and backed by our 60K+ employees and \n",
            "partners.\n",
            "* Indicates up to 12 Single-width (PCIe x8), and up to 8 Single-width (PCIe x16).\n",
            "Specification Sheet\n",
            "PowerEdge R760xa\n",
            "The Dell PowerEdge R760xa is a high-\n",
            "performance scale -as you grow server \n",
            "designed for use cases like\n",
            "• AI/ML/DL Training and Inferencing \n",
            "• Digital Twins, render graphics\n",
            "• Virtualization and VDI graphics\n",
            "\n",
            "\n",
            "=== chunk #3, word count:148 ===\n",
            "Feature Technical Specifications\n",
            "Processor Up to two 4th Generation Intel Xeon Scalable processor with up to 56 cores per processor and optional Intel® QuickAssist\n",
            "Technology\n",
            "Up to two 5th Generation Intel Xeon Scalable processor with up to 64 cores per processor and optional Intel® QuickAssist \n",
            "Technology  \n",
            "Memory • 32 DDR5 DIMM slot, supports RDIMM 8 TB max\n",
            "• Speeds up to 4800 MT/s on the 4th Generation Intel® Xeon Scalable processor\n",
            "• Speeds up to 5600 MT/s on the 5th Generation Intel® Xeon Scalable processor\n",
            "• Supports registered ECC DDR5 DIMMs only\n",
            "Storage controllers • Internal controllers: PERC H965i, PERC H755, PERC H755N, PERC H355, HBA355i, HBA465i\n",
            "• Internal Boot: Boot Optimized Storage Subsystem (BOSS-N1): HWRAID 2 x M.2 NVMe SSDs, or USB\n",
            "• External HBA (non-RAID): HBA355e, HBA465e, H965e\n",
            "• Software RAID: S160\n",
            "Drive Bays Front bays: \n",
            "• Up to 6 x E3.S Gen5 NVMe, max 46.\n",
            "\n",
            "\n",
            "=== chunk #4, word count:133 ===\n",
            "S Gen5 NVMe, max 46.08 TB\n",
            "• Up to 6 x 2.5-inch NVMe, max 92.16 TB\n",
            "• Up to 8 x 2.5-inch SAS/SATA/NVMe, max 122.88 TB\n",
            "Power Supplies • 3200 W Titanium  277–305 VAC or 336 HVDC, hot swap redundant\n",
            "• 2800 W Titanium 200–240 VAC or 240 HVDC, hot swap redundant\n",
            "• 2400 W Platinum 100–240 VAC or 240 HVDC, hot swap redundant\n",
            "Cooling Options • Air cooling\n",
            "• Optional Direct Liquid Cooling (DLC)\n",
            "Note: DLC is a rack solution and requires rack manifolds and a cooling distribution unit (CDU) to operate.\n",
            "Fans • Standard (STD) fan\n",
            "• Up to six hot plug fans \n",
            "Dimensions • Height – 86.8 mm (3.41 inches)\n",
            "• Width – 482 mm (18.97 inches)\n",
            "• Depth – 946.73 mm (37.27 inches) - without bezel\n",
            "                     932.89 mm (36.\n",
            "\n",
            "\n",
            "=== chunk #5, word count:172 ===\n",
            "27 inches) - without bezel\n",
            "                     932.89 mm (36.73 inches) - with bezel\n",
            "Form Factor 2U rack server\n",
            "Embedded Management • iDRAC9\n",
            "• iDRAC Direct\n",
            "• iDRAC RESTful API with Redfish\n",
            "• iDRAC Service Module\n",
            "• Quick Sync 2 wireless module\n",
            "Bezel Optional LCD bezel or security bezel\n",
            "OpenManage Software • OpenManage Enterprise\n",
            "• OpenManage Power Manager plugin\n",
            "• OpenManage Service plugin\n",
            "• OpenManage Update Manager plugin\n",
            "• CloudIQ for PowerEdge plug in\n",
            "• OpenManage Enterprise Integration for VMware vCenter\n",
            "• OpenManage Integration for Microsoft System Center\n",
            "• OpenManage Integration with Windows Admin Center\n",
            "Mobility OpenManage Mobile\n",
            "OpenManage Integrations • BMC Truesight\n",
            "• Microsoft System Center\n",
            "• OpenManage Integration with ServiceNow\n",
            "• Red Hat Ansible Modules\n",
            "• Terraform Providers\n",
            "• VMware vCenter and vRealize Operations Manager\n",
            "Security • Cryptographically signed firmware\n",
            "• Data at Rest Encryption (SEDs with local or external \n",
            "key mgmt)\n",
            "• Secure Boot\n",
            "• Secured Component Verification (Hardware integrity check)\n",
            "• Secure Erase\n",
            "• Silicon Root of Trust\n",
            "• System Lockdown (requires iDRAC9 Enterprise or \n",
            "Datacenter)\n",
            "• TPM 2.0 FIPS,\n",
            "\n",
            "\n",
            "=== chunk #6, word count:43 ===\n",
            "0 FIPS, CC-TCG certified, TPM 2.0 China NationZ\n",
            "Embedded NIC 2 x 1GbE LOM card (optional)\n",
            "Network Options 1 x OCP card 3.0 (optional)\n",
            "NOTE: The system allows either LOM card or an OCP card or both to be installed in the system.\n",
            "\n",
            "\n",
            "=== chunk #7, word count:164 ===\n",
            "GPU Options Up to 4 x 400 W DW PCIe x16 GPU cards\n",
            "Up to 12 x 75 W SW PCIe x8 GPU cards\n",
            "Ports Front Ports \n",
            "• 1 x iDRAC Direct (Micro-AB USB) port\n",
            "• 1 x USB 2.0\n",
            "• 1 x VGA\n",
            "Rear Ports\n",
            "• 1 x Dedicated iDRAC Ethernet port \n",
            "• 1 x USB 2.0\n",
            "• 1 x USB 3.0\n",
            "• 1 x Serial (optional)\n",
            "• 1 x VGA (optional for Direct Liquid Cooling configuration)\n",
            "Internal Ports\n",
            "• 1 x USB 3.0 (optional)\n",
            "PCIe  Up to twelve PCIe slots (x16 connector)\n",
            "• 4 x16 Rear Full height, Half length + 4 x16 Front Full height, Full length DW\n",
            "• 4 x16 Rear Full height, Half length + 8 x 8 Front Full height, Full length SW\n",
            "Operating System and Hypervisors • Canonical Ubuntu Server LTS\n",
            "• Microsoft Windows Server with Hyper-V\n",
            "• Red Hat Enterprise Linux\n",
            "• SUSE Linux Enterprise Server\n",
            "• VMware ESXi\n",
            "For specifications and interoperability details, see Dell.com/OSsupport.\n",
            "\n",
            "\n",
            "=== chunk #8, word count:34 ===\n",
            "OEM-ready version available From bezel to BIOS to packaging, your servers can look and feel as if they were designed and built by you. For more information, \n",
            "visit Dell.com -> Solutions -> OEM Solutions..\n",
            "\n",
            "\n",
            "=== chunk #9, word count:102 ===\n",
            "Learn more about our \n",
            "systems management \n",
            "solutions\n",
            "Contact a Dell \n",
            "Technologies Expert \n",
            "for Sales or Support\n",
            "Search our \n",
            "Resource Library\n",
            "Follow PowerEdge \n",
            "servers on Twitter\n",
            "Learn more about our \n",
            "PowerEdge servers]\n",
            "Discover more about PowerEdge servers\n",
            "APEX on Demand\n",
            "APEX Flex on Demand Acquire the technology you need to support your changing business with  \n",
            "payments that scale to match actual usage. For more information, visit  \n",
            "www.delltechnologies.com/en-us/payment-solutions/flexible-consumption/flex-on-demand.htm.\n",
            "Copyright © 2024 Dell Inc. or its subsidiaries.  All Rights Reserved.  Dell Technologies, Dell, and other trademarks are \n",
            "trademarks of Dell Inc. or its subsidiaries.  Other trademarks may be trademarks of their respective owners.  \n",
            " \n",
            "July 2024\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from pprint import pprint\n",
        "\n",
        "splitter = SentenceSplitter(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=20,\n",
        ")\n",
        "\n",
        "nodes = splitter.get_nodes_from_documents(documents)\n",
        "for i, _ in enumerate(nodes):\n",
        "    print(f\"=== chunk #{i}, word count:{len(nodes[i].text.split())} ===\")\n",
        "    print(nodes[i].text)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df0677ba-50ae-4cda-9e8c-861937cf5df0",
      "metadata": {
        "id": "df0677ba-50ae-4cda-9e8c-861937cf5df0"
      },
      "source": [
        "### Semantic chunking"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baebe8f2-1db3-4623-af9e-76768577dea0",
      "metadata": {
        "id": "baebe8f2-1db3-4623-af9e-76768577dea0"
      },
      "source": [
        "This is a relatively new concept. Instead of chunking text with a fixed chunk size, the semantic splitter adaptively picks the breakpoint in-between sentences using embedding similarity. This ensures that a \"chunk\" contains sentences that are semantically related to each other. Notice the longer time it takes to do the chunking compared to the previous two methods since the creation of embeddings and computation of cosine similiraties is more computationally expensive.\n",
        "\n",
        "The data scientist will have to experiment different values for the breakpoint percentile threshold. The higher the threshold the lower the number of breaking points, ie the less chunks.\n",
        "\n",
        "<b>IMPORTANT:</b> This algorithm makes several calls to Nvidia's embedding model. Please do not try many combinations of the threshold or you might trigger the API call throttling for your Nvidia account"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#apikey = os.environ[\"NVIDIA_API_KEY\"]\n",
        "#change from OS variable import to using Google Colab secret\n",
        "from google.colab import userdata\n",
        "apikey = userdata.get('apikey')\n",
        "os.environ[\"NVIDIA_API_KEY\"] = apikey\n",
        "#print(apikey)"
      ],
      "metadata": {
        "id": "67yIsWc3xP7t"
      },
      "id": "67yIsWc3xP7t",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d6a1f1d5-2c3f-4cb8-88a5-f2dcee9ad204",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6a1f1d5-2c3f-4cb8-88a5-f2dcee9ad204",
        "outputId": "894d877b-f9cb-49c0-9c8e-00ddc64e6970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== chunk #0, word count:81 ===\n",
            "PowerEdge R760xa\n",
            "High performance, scalable server for \n",
            "intensive GPU applications\n",
            "The Dell PowerEdge R760xa, is a purpose-built server designed to boost acceleration performance across the widest \n",
            "range of customer needs.\n",
            "Innovate at scale with challenging and emerging workloads\n",
            "Maximize your workload performance and boost outcomes with scale as you grow compute, flexibly supporting a wide range \n",
            "of GPUs in a dual-socket/2U air-cooled server, accelerating applications from AI training and inferencing to Digital Twins to \n",
            "performance graphics and dense power-user collaboration environments.\n",
            "\n",
            "\n",
            "\n",
            "=== chunk #1, word count:376 ===\n",
            "• Leverage a powerful architecture and the power of two 4th or 5th Generation Intel® Xeon® processors with high core count \n",
            "of up to 64 cores and the latest on-chip innovations to boost AI and ML operations\n",
            "• Up to four double-width PCIe Gen5 accelerators or up to 12 single-width* PCIe accelerators to break through the density \n",
            "boundaries of todays and tomorrow’s computing\n",
            "• Support for PCIe GPU adapters from NVIDIA, AMD, and Intel, delivering superior outcomes with one platform\n",
            "Accelerated I/O throughput\n",
            "• Deploy latest generation technologies including DDR5, Gen4 NVLink, PCIe Gen 5, and E3.S NVMe SSDs to push the \n",
            "boundaries of data flow and computing possibilities.\n",
            "• Scale up your needs supporting up to 32 DDR5 memory DIMM slots, up to eight drives, and PCIe Gen 5 expansion slots\n",
            "• Air-cooled design with front-facing accelerators enables better cooling and supports higher TDP accelerators (up to 400 W) \n",
            "Cyber Resilient Architecture for Zero Trust IT environment & operations\n",
            "Security is integrated into every phase of the PowerEdge lifecycle, including protected supply chain and factory-to-site integrity \n",
            "assurance. Silicon-based root of trust anchors end-to-end boot resilience while Multi-Factor Authentication (MFA) and role-based \n",
            "access controls ensure trusted operations.\n",
            "Increase efficiency and accelerate operations with autonomous collaboration\n",
            "The Dell OpenManage™ systems management portfolio delivers a secure, efficient, and comprehensive solution for PowerEdge \n",
            "servers. Simplify, automate and centralize one-to-many management with the OpenManage Enterprise console and iDRAC.\n",
            "Sustainability\n",
            "From recycled materials in our products and packaging, to thoughtful, innovative options for energy efficiency, the PowerEdge \n",
            "portfolio is designed to make, deliver, and recycle products to help reduce the carbon footprint and lower your operation costs. \n",
            "We even make it easy to retire legacy systems responsibly with Dell Technologies Services.\n",
            "Rest easier with Dell Technologies Services\n",
            "Maximize your PowerEdge Servers with comprehensive services ranging from \n",
            "Consulting, to ProDeploy and ProSupport suites, Data Migration and more \n",
            "– available across 170 countries and backed by our 60K+ employees and \n",
            "partners.\n",
            "* Indicates up to 12 Single-width (PCIe x8), and up to 8 Single-width (PCIe x16).\n",
            "Specification Sheet\n",
            "PowerEdge R760xa\n",
            "The Dell PowerEdge R760xa is a high-\n",
            "performance scale -as you grow server \n",
            "designed for use cases like\n",
            "• AI/ML/DL Training and Inferencing \n",
            "• Digital Twins, render graphics\n",
            "• Virtualization and VDI graphics\n",
            "\n",
            "\n",
            "\n",
            "=== chunk #2, word count:645 ===\n",
            "Feature Technical Specifications\n",
            "Processor Up to two 4th Generation Intel Xeon Scalable processor with up to 56 cores per processor and optional Intel® QuickAssist\n",
            "Technology\n",
            "Up to two 5th Generation Intel Xeon Scalable processor with up to 64 cores per processor and optional Intel® QuickAssist \n",
            "Technology  \n",
            "Memory • 32 DDR5 DIMM slot, supports RDIMM 8 TB max\n",
            "• Speeds up to 4800 MT/s on the 4th Generation Intel® Xeon Scalable processor\n",
            "• Speeds up to 5600 MT/s on the 5th Generation Intel® Xeon Scalable processor\n",
            "• Supports registered ECC DDR5 DIMMs only\n",
            "Storage controllers • Internal controllers: PERC H965i, PERC H755, PERC H755N, PERC H355, HBA355i, HBA465i\n",
            "• Internal Boot: Boot Optimized Storage Subsystem (BOSS-N1): HWRAID 2 x M.2 NVMe SSDs, or USB\n",
            "• External HBA (non-RAID): HBA355e, HBA465e, H965e\n",
            "• Software RAID: S160\n",
            "Drive Bays Front bays: \n",
            "• Up to 6 x E3.S Gen5 NVMe, max 46.08 TB\n",
            "• Up to 6 x 2.5-inch NVMe, max 92.16 TB\n",
            "• Up to 8 x 2.5-inch SAS/SATA/NVMe, max 122.88 TB\n",
            "Power Supplies • 3200 W Titanium  277–305 VAC or 336 HVDC, hot swap redundant\n",
            "• 2800 W Titanium 200–240 VAC or 240 HVDC, hot swap redundant\n",
            "• 2400 W Platinum 100–240 VAC or 240 HVDC, hot swap redundant\n",
            "Cooling Options • Air cooling\n",
            "• Optional Direct Liquid Cooling (DLC)\n",
            "Note: DLC is a rack solution and requires rack manifolds and a cooling distribution unit (CDU) to operate.\n",
            "Fans • Standard (STD) fan\n",
            "• Up to six hot plug fans \n",
            "Dimensions • Height – 86.8 mm (3.41 inches)\n",
            "• Width – 482 mm (18.97 inches)\n",
            "• Depth – 946.73 mm (37.27 inches) - without bezel\n",
            "                     932.89 mm (36.73 inches) - with bezel\n",
            "Form Factor 2U rack server\n",
            "Embedded Management • iDRAC9\n",
            "• iDRAC Direct\n",
            "• iDRAC RESTful API with Redfish\n",
            "• iDRAC Service Module\n",
            "• Quick Sync 2 wireless module\n",
            "Bezel Optional LCD bezel or security bezel\n",
            "OpenManage Software • OpenManage Enterprise\n",
            "• OpenManage Power Manager plugin\n",
            "• OpenManage Service plugin\n",
            "• OpenManage Update Manager plugin\n",
            "• CloudIQ for PowerEdge plug in\n",
            "• OpenManage Enterprise Integration for VMware vCenter\n",
            "• OpenManage Integration for Microsoft System Center\n",
            "• OpenManage Integration with Windows Admin Center\n",
            "Mobility OpenManage Mobile\n",
            "OpenManage Integrations • BMC Truesight\n",
            "• Microsoft System Center\n",
            "• OpenManage Integration with ServiceNow\n",
            "• Red Hat Ansible Modules\n",
            "• Terraform Providers\n",
            "• VMware vCenter and vRealize Operations Manager\n",
            "Security • Cryptographically signed firmware\n",
            "• Data at Rest Encryption (SEDs with local or external \n",
            "key mgmt)\n",
            "• Secure Boot\n",
            "• Secured Component Verification (Hardware integrity check)\n",
            "• Secure Erase\n",
            "• Silicon Root of Trust\n",
            "• System Lockdown (requires iDRAC9 Enterprise or \n",
            "Datacenter)\n",
            "• TPM 2.0 FIPS, CC-TCG certified, TPM 2.0 China NationZ\n",
            "Embedded NIC 2 x 1GbE LOM card (optional)\n",
            "Network Options 1 x OCP card 3.0 (optional)\n",
            "NOTE: The system allows either LOM card or an OCP card or both to be installed in the system.\n",
            "GPU Options Up to 4 x 400 W DW PCIe x16 GPU cards\n",
            "Up to 12 x 75 W SW PCIe x8 GPU cards\n",
            "Ports Front Ports \n",
            "• 1 x iDRAC Direct (Micro-AB USB) port\n",
            "• 1 x USB 2.0\n",
            "• 1 x VGA\n",
            "Rear Ports\n",
            "• 1 x Dedicated iDRAC Ethernet port \n",
            "• 1 x USB 2.0\n",
            "• 1 x USB 3.0\n",
            "• 1 x Serial (optional)\n",
            "• 1 x VGA (optional for Direct Liquid Cooling configuration)\n",
            "Internal Ports\n",
            "• 1 x USB 3.0 (optional)\n",
            "PCIe  Up to twelve PCIe slots (x16 connector)\n",
            "• 4 x16 Rear Full height, Half length + 4 x16 Front Full height, Full length DW\n",
            "• 4 x16 Rear Full height, Half length + 8 x 8 Front Full height, Full length SW\n",
            "Operating System and Hypervisors • Canonical Ubuntu Server LTS\n",
            "• Microsoft Windows Server with Hyper-V\n",
            "• Red Hat Enterprise Linux\n",
            "• SUSE Linux Enterprise Server\n",
            "• VMware ESXi\n",
            "For specifications and interoperability details, see Dell.com/OSsupport.\n",
            "\n",
            "\n",
            "\n",
            "=== chunk #3, word count:34 ===\n",
            "OEM-ready version available From bezel to BIOS to packaging, your servers can look and feel as if they were designed and built by you. For more information, \n",
            "visit Dell.com -> Solutions -> OEM Solutions..\n",
            "\n",
            "\n",
            "=== chunk #4, word count:91 ===\n",
            "Learn more about our \n",
            "systems management \n",
            "solutions\n",
            "Contact a Dell \n",
            "Technologies Expert \n",
            "for Sales or Support\n",
            "Search our \n",
            "Resource Library\n",
            "Follow PowerEdge \n",
            "servers on Twitter\n",
            "Learn more about our \n",
            "PowerEdge servers]\n",
            "Discover more about PowerEdge servers\n",
            "APEX on Demand\n",
            "APEX Flex on Demand Acquire the technology you need to support your changing business with  \n",
            "payments that scale to match actual usage. For more information, visit  \n",
            "www.delltechnologies.com/en-us/payment-solutions/flexible-consumption/flex-on-demand.htm.\n",
            "Copyright © 2024 Dell Inc. or its subsidiaries.  All Rights Reserved.  Dell Technologies, Dell, and other trademarks are \n",
            "trademarks of Dell Inc. or its subsidiaries.  \n",
            "\n",
            "\n",
            "=== chunk #5, word count:11 ===\n",
            "Other trademarks may be trademarks of their respective owners.  \n",
            " \n",
            "July 2024\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
        "from llama_index.embeddings.nvidia import NVIDIAEmbedding\n",
        "\n",
        "embed_model = NVIDIAEmbedding(truncate=\"END\")\n",
        "\n",
        "splitter = SemanticSplitterNodeParser(\n",
        "    buffer_size=1, breakpoint_percentile_threshold=95, embed_model=embed_model\n",
        ")\n",
        "nodes = splitter.get_nodes_from_documents(documents)\n",
        "for i, _ in enumerate(nodes):\n",
        "    print(f\"=== chunk #{i}, word count:{len(nodes[i].text.split())} ===\")\n",
        "    print(nodes[i].text)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "184025df-5086-4e7f-8e96-9d322fe8c31a",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "184025df-5086-4e7f-8e96-9d322fe8c31a"
      },
      "source": [
        "### End of Lab 8"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}