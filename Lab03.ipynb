{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StrategicalIT/PipedPiperAI/blob/main/Lab03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6cae130-b662-46d8-9b14-da63c83f8b31",
      "metadata": {
        "id": "a6cae130-b662-46d8-9b14-da63c83f8b31"
      },
      "source": [
        "# LAB3: Sentence Embeddings with SBERT\n",
        "In this lab we are going to explore sentence embeddings using [Sentence Transformers a.k.a \"SBERT\"](https://sbert.net/).\n",
        "\n",
        "This tool was created in 2018 but it is still actively used and developed. Its [GitHub repo](https://github.com/UKPLab/sentence-transformers/) has 16K stars and 200 contributors. As it names indicates it leverages transformers which use the \"attention\" mechanism introduced by Google in 2017. You can choose from a \"wide\" selection of over 5,000 :) pre-trained Sentence Transformers models available on ðŸ¤— Hugging Face. A common way of deciding what model to use is to check the [Massive Text Embeddings Benchmark (MTEB) leaderboard](https://huggingface.co/spaces/mteb/leaderboard)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4a981d6-9821-4ad0-8913-5c00a8828845",
      "metadata": {
        "id": "f4a981d6-9821-4ad0-8913-5c00a8828845"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9189748d-cb87-4066-83ed-8843d49e7118",
      "metadata": {
        "id": "9189748d-cb87-4066-83ed-8843d49e7118"
      },
      "source": [
        "The first step is to install the necessary libraries. In this case we will install the [sentence transformers](https://pypi.org/project/sentence-transformers/) Python library. This library is a popular collection of tools and models to compute embeddings for sentences, paragraphs and images. The models are based on transformer networks like BERT / RoBERTa / XLM-RoBERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb3dbdb8-2c89-40b9-a1a5-532401e9ec5a",
      "metadata": {
        "id": "fb3dbdb8-2c89-40b9-a1a5-532401e9ec5a"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2545d976-c99f-4a44-a830-b88afbdf4195",
      "metadata": {
        "id": "2545d976-c99f-4a44-a830-b88afbdf4195"
      },
      "source": [
        "Let's import a few things we need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ae207cd-f93f-48c5-90ef-ab838e012fe7",
      "metadata": {
        "id": "6ae207cd-f93f-48c5-90ef-ab838e012fe7"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "830d0edc-8347-4182-8f49-632edcae95a4",
      "metadata": {
        "id": "830d0edc-8347-4182-8f49-632edcae95a4"
      },
      "source": [
        "## Load the model and create embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5202b6d7-7643-44c1-9227-6ed9a60bb325",
      "metadata": {
        "id": "5202b6d7-7643-44c1-9227-6ed9a60bb325"
      },
      "source": [
        "We are going to create a model by pulling it from HuggingFace. This one is about 440MB so it should come down in a minute or less"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14432aec-a48f-42a3-83e4-470a827950d4",
      "metadata": {
        "id": "14432aec-a48f-42a3-83e4-470a827950d4"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer('bert-base-nli-mean-tokens') #all-MiniLM-L6-v2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2978257a-c306-4543-b7b2-a522f7fd4465",
      "metadata": {
        "id": "2978257a-c306-4543-b7b2-a522f7fd4465"
      },
      "source": [
        "Let's create a small corpus with a few sentences and use the model to encode them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b46582ab-3ecc-433f-8533-e4aa557ed1b9",
      "metadata": {
        "id": "b46582ab-3ecc-433f-8533-e4aa557ed1b9"
      },
      "outputs": [],
      "source": [
        "sentences = [\n",
        "       \"I ate dinner.\",\n",
        "       \"We had a three-course meal.\",\n",
        "       \"Brad came to dinner with us.\",\n",
        "       \"He loves fish tacos.\",\n",
        "       \"In the end, we all felt like we ate too much.\",\n",
        "       \"We all agreed; it was a magnificent evening.\"]\n",
        "sentence_embeddings = model.encode(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0de9b6e9-a467-45dd-8f36-36549f57d2f6",
      "metadata": {
        "id": "0de9b6e9-a467-45dd-8f36-36549f57d2f6"
      },
      "source": [
        "The sentences have now been encoded and we can examine them. Notice below that size of the vectors this model creates. Different models using different number of dimensions.\n",
        "\n",
        "The variable \"sentence_embeddings\" we have just created is a list so what you are looking at is the embedding for the first sentence, ie the one with index=0. As you can see it includes also negative values.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09b7bebe-49ef-4e79-bd39-322cc4275c4c",
      "metadata": {
        "id": "09b7bebe-49ef-4e79-bd39-322cc4275c4c"
      },
      "outputs": [],
      "source": [
        "print('The size of a vector is', len(sentence_embeddings[0]))\n",
        "print('This is the embedding vector for the first sentence', sentence_embeddings[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9aa8cc28-0058-4c16-84ab-962b61ecabcf",
      "metadata": {
        "id": "9aa8cc28-0058-4c16-84ab-962b61ecabcf"
      },
      "source": [
        "## Calculate similarities"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ad918a7-7abe-4980-a5b3-01608feafdd2",
      "metadata": {
        "id": "2ad918a7-7abe-4980-a5b3-01608feafdd2"
      },
      "source": [
        "We can use the \"similarity\" method to compare a query sentence to all the embeddings in our corpus. But first we need to convert our query into a vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd6376d0-e739-4e20-841a-105faaeaf90b",
      "metadata": {
        "id": "fd6376d0-e739-4e20-841a-105faaeaf90b"
      },
      "outputs": [],
      "source": [
        "query = [\"I had pizza and pasta for dinner\"]\n",
        "query_embedding = model.encode(query)\n",
        "similarities = model.similarity(query_embedding, sentence_embeddings)\n",
        "for s in range(0,len(sentences)):\n",
        "    print(f'{sentences[s]:<50}', \" : \", similarities[0][s].detach().numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85055943-3190-4935-ae24-e676616da70d",
      "metadata": {
        "id": "85055943-3190-4935-ae24-e676616da70d"
      },
      "source": [
        "The closer the similarity score is to 1 the closer semantically the query is to that sentence. Does the result make sense?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc809e09-7b2d-42d2-823e-08e7ece07318",
      "metadata": {
        "id": "dc809e09-7b2d-42d2-823e-08e7ece07318"
      },
      "source": [
        "## Ideas to explore further"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c00fdc2b-2879-46f8-aa43-bbfd43930be6",
      "metadata": {
        "id": "c00fdc2b-2879-46f8-aa43-bbfd43930be6"
      },
      "source": [
        "Try changing the queries and observe the results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "184025df-5086-4e7f-8e96-9d322fe8c31a",
      "metadata": {
        "id": "184025df-5086-4e7f-8e96-9d322fe8c31a"
      },
      "source": [
        "### End of Lab 3"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}