{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StrategicalIT/PipedPiperAI/blob/main/Lab04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6cae130-b662-46d8-9b14-da63c83f8b31",
      "metadata": {
        "id": "a6cae130-b662-46d8-9b14-da63c83f8b31"
      },
      "source": [
        "# LAB4: Using an embedding model from NIM API\n",
        "In this lab we are going to leverage Nvdia's NIM API to generate embeddings. There are multiple embedding models available. You can check them out at [https://build.nvidia.com/explore/retrieval](https://build.nvidia.com/explore/retrieval).\n",
        "\n",
        "You can interact with the models online from your web browser but we will do so programatically using Python.  You can also use the API reference site to get more information about each embedding model as well as the actual endpoints exposed by the REST API . It can be accessed at [https://docs.api.nvidia.com/nim/reference/retrieval-apis](https://docs.api.nvidia.com/nim/reference/retrieval-apis). You will find the models by scrolling down to the \"Retrieval\" section"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4a981d6-9821-4ad0-8913-5c00a8828845",
      "metadata": {
        "id": "f4a981d6-9821-4ad0-8913-5c00a8828845"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9189748d-cb87-4066-83ed-8843d49e7118",
      "metadata": {
        "id": "9189748d-cb87-4066-83ed-8843d49e7118"
      },
      "source": [
        "The first step is to install the necessary libraries. In this case we will install the openai Python library. This is considered the de-facto industry standard and most providers including Nvidia NIM use it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb3dbdb8-2c89-40b9-a1a5-532401e9ec5a",
      "metadata": {
        "id": "fb3dbdb8-2c89-40b9-a1a5-532401e9ec5a"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77c1fdd6-4f4b-473a-9f8e-f36d2c568989",
      "metadata": {
        "id": "77c1fdd6-4f4b-473a-9f8e-f36d2c568989"
      },
      "source": [
        "We are also going to need NumPy to help us compute the cosine similarity a bit later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f25c18c7-6fb2-40bd-bb9c-13972d2920d0",
      "metadata": {
        "id": "f25c18c7-6fb2-40bd-bb9c-13972d2920d0"
      },
      "outputs": [],
      "source": [
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b46cce7-e5eb-4118-a7ae-500b526720ae",
      "metadata": {
        "id": "5b46cce7-e5eb-4118-a7ae-500b526720ae"
      },
      "source": [
        "Let's import a few things from openai and numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c32330ce-ccbc-4cec-9229-87ab44de68a0",
      "metadata": {
        "id": "c32330ce-ccbc-4cec-9229-87ab44de68a0"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77b2dfca-a15e-49f3-b1e8-424febccc972",
      "metadata": {
        "id": "77b2dfca-a15e-49f3-b1e8-424febccc972"
      },
      "source": [
        "## Connect to the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08bdb8a6-4dcd-426d-be1b-9f5010e4e244",
      "metadata": {
        "id": "08bdb8a6-4dcd-426d-be1b-9f5010e4e244"
      },
      "source": [
        "Next we read the NIM API key from the environment and store it in a variable called \"apikey\" for future use. You can uncomment the \"print\" command if you want to validate that it has been read correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d209b55-3eed-417a-b483-7a30291c0ce5",
      "metadata": {
        "id": "0d209b55-3eed-417a-b483-7a30291c0ce5"
      },
      "outputs": [],
      "source": [
        "#import os\n",
        "#apikey = os.environ[\"NVIDIA_API_KEY\"]\n",
        "#change from OS variable import to using Google Colab secret\n",
        "from google.colab import userdata\n",
        "apikey = userdata.get('apikey')\n",
        "#print(apikey)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5202b6d7-7643-44c1-9227-6ed9a60bb325",
      "metadata": {
        "id": "5202b6d7-7643-44c1-9227-6ed9a60bb325"
      },
      "source": [
        "Let's create a client instance. This client will be able to access all models. No need for a separate client connection for each model. Notice how were we are specifying the API key. Put your own API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14432aec-a48f-42a3-83e4-470a827950d4",
      "metadata": {
        "id": "14432aec-a48f-42a3-83e4-470a827950d4"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(\n",
        "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
        "  api_key = apikey\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2978257a-c306-4543-b7b2-a522f7fd4465",
      "metadata": {
        "id": "2978257a-c306-4543-b7b2-a522f7fd4465"
      },
      "source": [
        "We can now use the client connection to compute the embedding for any input string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b46582ab-3ecc-433f-8533-e4aa557ed1b9",
      "metadata": {
        "id": "b46582ab-3ecc-433f-8533-e4aa557ed1b9"
      },
      "outputs": [],
      "source": [
        "response = client.embeddings.create(\n",
        "    input=[\"I like good weather\"],\n",
        "    model=\"nvidia/nv-embedqa-e5-v5\",\n",
        "    encoding_format=\"float\",\n",
        "    extra_body={\"input_type\": \"query\", \"truncate\": \"NONE\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0de9b6e9-a467-45dd-8f36-36549f57d2f6",
      "metadata": {
        "id": "0de9b6e9-a467-45dd-8f36-36549f57d2f6"
      },
      "source": [
        "Notice how we using the \"model\" parameter to request embeddings from a specific model. Model \"nv-embedqa-e5-v5\" is part of Nvidia's NeMo Retriever.\n",
        "\n",
        "Let's find out how many dimensions this model is using and examine show the embedding of our input string. For cleanness we will show only the first 6 dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09b7bebe-49ef-4e79-bd39-322cc4275c4c",
      "metadata": {
        "id": "09b7bebe-49ef-4e79-bd39-322cc4275c4c"
      },
      "outputs": [],
      "source": [
        "print(\"The vector size of this embedding model is :\", len(response.data[0].embedding))\n",
        "print(response.data[0].embedding[:6])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd00b2f5-a4bd-4729-9cf8-71a4f159fae5",
      "metadata": {
        "id": "dd00b2f5-a4bd-4729-9cf8-71a4f159fae5"
      },
      "source": [
        "## Calculate similarity between vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ad918a7-7abe-4980-a5b3-01608feafdd2",
      "metadata": {
        "id": "2ad918a7-7abe-4980-a5b3-01608feafdd2"
      },
      "source": [
        "We can use the \"similarity\" method to compare a query sentence to all the embeddings in our corpus."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f22acb6b-dee7-4d03-9c67-873879c0e5a8",
      "metadata": {
        "id": "f22acb6b-dee7-4d03-9c67-873879c0e5a8"
      },
      "source": [
        "We will see in a later lesson how similarities are typically done by the vector database but for now we can define our own cosine similarity using NumPy functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14c74256-1d2f-4978-a60b-3c45d8dfbe63",
      "metadata": {
        "id": "14c74256-1d2f-4978-a60b-3c45d8dfbe63"
      },
      "outputs": [],
      "source": [
        "def cosine(u, v):\n",
        "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68678cf0-4a92-4079-a984-033044343a51",
      "metadata": {
        "id": "68678cf0-4a92-4079-a984-033044343a51"
      },
      "source": [
        "We can now use a second sentence to obtain a vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db1b154d-7fac-4b88-ae77-da1102bd3926",
      "metadata": {
        "id": "db1b154d-7fac-4b88-ae77-da1102bd3926"
      },
      "outputs": [],
      "source": [
        "query = client.embeddings.create(\n",
        "    input=[\"Today is going to be sunny\"],\n",
        "    model=\"nvidia/nv-embedqa-e5-v5\",\n",
        "    encoding_format=\"float\",\n",
        "    extra_body={\"input_type\": \"query\", \"truncate\": \"NONE\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b65b16da-1bf0-45f0-86be-07f2d6e514d9",
      "metadata": {
        "id": "b65b16da-1bf0-45f0-86be-07f2d6e514d9"
      },
      "source": [
        "Let's calculate the similarity between both embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e18c364-b18f-4874-b6d4-fe293a372eb3",
      "metadata": {
        "id": "4e18c364-b18f-4874-b6d4-fe293a372eb3"
      },
      "outputs": [],
      "source": [
        "sim = cosine(query.data[0].embedding, response.data[0].embedding)\n",
        "print(\"The similarity is : \", sim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85055943-3190-4935-ae24-e676616da70d",
      "metadata": {
        "id": "85055943-3190-4935-ae24-e676616da70d"
      },
      "source": [
        "The closer the similarity score is to 1 the closer semantically the query is to that sentence. Does the result make sense?\n",
        "\n",
        "You can experiment with other embedding models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7058cfa2-11a2-4866-8cf0-79507d569ad3",
      "metadata": {
        "id": "7058cfa2-11a2-4866-8cf0-79507d569ad3"
      },
      "source": [
        "## Try with a different embedding model\n",
        "An important role of the Data Scientist is to find the components of the solution that produce the best results for a given use case. For example, in order to obtain more accurate results from a similarity search they might evaluate multiple embedding models. Let's run the same two sentences through a different embedding model and compare the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3028a9c5-f9d8-4d10-9d0d-fdb21e637dcd",
      "metadata": {
        "id": "3028a9c5-f9d8-4d10-9d0d-fdb21e637dcd"
      },
      "outputs": [],
      "source": [
        "response = client.embeddings.create(\n",
        "    input=[\"I like good weather\"],\n",
        "    model=\"nvidia/nv-embed-v1\",\n",
        "    encoding_format=\"float\",\n",
        "    extra_body={\"input_type\": \"query\", \"truncate\": \"NONE\"}\n",
        ")\n",
        "\n",
        "query = client.embeddings.create(\n",
        "    input=[\"Today is going to be sunny\"],\n",
        "    model=\"nvidia/nv-embed-v1\",\n",
        "    encoding_format=\"float\",\n",
        "    extra_body={\"input_type\": \"query\", \"truncate\": \"NONE\"}\n",
        ")\n",
        "\n",
        "sim = cosine(query.data[0].embedding, response.data[0].embedding)\n",
        "print(\"The similarity is : \", sim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a36be702-27a9-4f07-8ce5-e39cab464694",
      "metadata": {
        "id": "a36be702-27a9-4f07-8ce5-e39cab464694"
      },
      "source": [
        "In your opinion, what model produced better results?\n",
        "\n",
        "Feel free to do further testing by using other sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "184025df-5086-4e7f-8e96-9d322fe8c31a",
      "metadata": {
        "id": "184025df-5086-4e7f-8e96-9d322fe8c31a"
      },
      "source": [
        "### End of Lab 4"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}