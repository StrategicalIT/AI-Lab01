{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StrategicalIT/PipedPiperAI/blob/main/Lab02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6cae130-b662-46d8-9b14-da63c83f8b31",
      "metadata": {
        "id": "a6cae130-b662-46d8-9b14-da63c83f8b31"
      },
      "source": [
        "# LAB2: Word Embeddings with Word2Vec\n",
        "In this lab we are going to explore word embeddings using on of the most popular tools called \"Word2Vec.\n",
        "\n",
        "This tool was created by Google in 2013. It used a shallow neural network to create word embeddings and was able to use semantic understanding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d0fb4c5-08dc-45d0-a4e7-fbcb1057d6fa",
      "metadata": {
        "id": "7d0fb4c5-08dc-45d0-a4e7-fbcb1057d6fa"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9189748d-cb87-4066-83ed-8843d49e7118",
      "metadata": {
        "id": "9189748d-cb87-4066-83ed-8843d49e7118"
      },
      "source": [
        "The first step is to install the necessary libraries. In this case we will install the [gensim](https://pypi.org/project/gensim/) Python library. This library is popular for NLP (Natural Language Processing) use cases as it provides capabilities like topic modelling, document indexing and similarity retrieval.\n",
        "\n",
        "If you receive an **error message** about previous runtime versions (in Google Colab), **click restart** in the error message that pops up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fb3dbdb8-2c89-40b9-a1a5-532401e9ec5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb3dbdb8-2c89-40b9-a1a5-532401e9ec5a",
        "outputId": "74450ef0-c3e6-4d5b-e591-98141735179f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14a89838-296d-4b97-a91f-97552c4a5d0b",
      "metadata": {
        "id": "14a89838-296d-4b97-a91f-97552c4a5d0b"
      },
      "source": [
        "The gensim library comes package with multiple [models](https://radimrehurek.com/gensim/apiref.html). We are interested in Word2Vec.\n",
        "\n",
        "Let's start by importing it, but **before that** you need to click on the \"Runtime\" menu above and then select **\"Restart session\"** unless you got an error message on the previous step and have already restarted the session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6ae207cd-f93f-48c5-90ef-ab838e012fe7",
      "metadata": {
        "id": "6ae207cd-f93f-48c5-90ef-ab838e012fe7"
      },
      "outputs": [],
      "source": [
        "#did you restart the session before running this code block?\n",
        "import gensim\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31a36262-657e-44b4-a36a-c732d0b2965a",
      "metadata": {
        "id": "31a36262-657e-44b4-a36a-c732d0b2965a"
      },
      "source": [
        "## Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5202b6d7-7643-44c1-9227-6ed9a60bb325",
      "metadata": {
        "id": "5202b6d7-7643-44c1-9227-6ed9a60bb325"
      },
      "source": [
        "Word2Vec can work with large amounts of data but in our example we will with a small corpus of 3 sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b46582ab-3ecc-433f-8533-e4aa557ed1b9",
      "metadata": {
        "id": "b46582ab-3ecc-433f-8533-e4aa557ed1b9"
      },
      "outputs": [],
      "source": [
        "sentences = [\"this is sentence number one\", \"Here it is another one\",\"This makes it the third one\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0de9b6e9-a467-45dd-8f36-36549f57d2f6",
      "metadata": {
        "id": "0de9b6e9-a467-45dd-8f36-36549f57d2f6"
      },
      "source": [
        "To create the model Word2Vec we will need to pass our documents/sentences as a list where each item is a list of words from each document. We are going to call this structure \"corpus\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "09b7bebe-49ef-4e79-bd39-322cc4275c4c",
      "metadata": {
        "id": "09b7bebe-49ef-4e79-bd39-322cc4275c4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a82070b-b34e-4b44-b3e0-21c981dd7f5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['this', 'is', 'sentence', 'number', 'one'], ['here', 'it', 'is', 'another', 'one'], ['this', 'makes', 'it', 'the', 'third', 'one']]\n"
          ]
        }
      ],
      "source": [
        "corpus = []\n",
        "for s in sentences:\n",
        "    newlist = []\n",
        "    for w in s.split():\n",
        "        newlist.append(w.lower())\n",
        "    corpus.append(newlist)\n",
        "\n",
        "print(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31bc9dd7-eebe-4479-b988-b4577ca1bb5a",
      "metadata": {
        "id": "31bc9dd7-eebe-4479-b988-b4577ca1bb5a"
      },
      "source": [
        "## Creating and exploring the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f22acb6b-dee7-4d03-9c67-873879c0e5a8",
      "metadata": {
        "id": "f22acb6b-dee7-4d03-9c67-873879c0e5a8"
      },
      "source": [
        "It is time to create the model. Notice below how we are:\n",
        "- considering only words appearing once or more, ie with frequency greater than 1 by using min_count=1\n",
        "- requesting a vector size with 100 dimensions\n",
        "- setting the size of the sliding window to 5\n",
        "- using COBW. sg=0 means COBW (Continuous Bag of Words), wherease sg=1 means Skip-gram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "14c74256-1d2f-4978-a60b-3c45d8dfbe63",
      "metadata": {
        "id": "14c74256-1d2f-4978-a60b-3c45d8dfbe63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8abdd148-798f-47ed-cf18-d20632c4ac86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=11, vector_size=100, alpha=0.025>\n"
          ]
        }
      ],
      "source": [
        "model = Word2Vec(corpus, min_count = 1, vector_size = 100, window = 5, sg=0)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68678cf0-4a92-4079-a984-033044343a51",
      "metadata": {
        "id": "68678cf0-4a92-4079-a984-033044343a51"
      },
      "source": [
        "When we print the \"model\" we can see the size of the vocabulary.\n",
        "\n",
        "During the creation of the \"corpus\" construc before we used the \".lower()\" function to turn the words to lower case. If we remove that function the size of the vocabulary would increase to 12 because \"this\" and \"This\" won't be considered the same word."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c2eb333-0f53-423e-9360-0104f05fb5bf",
      "metadata": {
        "id": "7c2eb333-0f53-423e-9360-0104f05fb5bf"
      },
      "source": [
        "Next, let's display the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "db1b154d-7fac-4b88-ae77-da1102bd3926",
      "metadata": {
        "id": "db1b154d-7fac-4b88-ae77-da1102bd3926",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d79113d-c6f0-4c50-897e-a424d0781d28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['one', 'it', 'is', 'this', 'third', 'the', 'makes', 'another', 'here', 'number', 'sentence']\n"
          ]
        }
      ],
      "source": [
        "print(list(model.wv.key_to_index))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b65b16da-1bf0-45f0-86be-07f2d6e514d9",
      "metadata": {
        "id": "b65b16da-1bf0-45f0-86be-07f2d6e514d9"
      },
      "source": [
        "We can query the vocabulary to see position a certain word occupies. Bear in mind that the first item in a Python list is 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4e18c364-b18f-4874-b6d4-fe293a372eb3",
      "metadata": {
        "id": "4e18c364-b18f-4874-b6d4-fe293a372eb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb795bed-8b66-4582-f096-e49fddc7676c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ],
      "source": [
        "print(model.wv.key_to_index[\"is\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17bf06f1-66f1-4c1d-ac81-bd87724b8844",
      "metadata": {
        "id": "17bf06f1-66f1-4c1d-ac81-bd87724b8844"
      },
      "source": [
        "## Calculating similarities"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdeea060-a49e-4623-9a0a-4e6e608155e3",
      "metadata": {
        "id": "bdeea060-a49e-4623-9a0a-4e6e608155e3"
      },
      "source": [
        "We can use Word2Vec to compute the similarity. These 2 words should be reasonably similar. The closer the similarity is to \"1\", the more semantically related they are"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7edaeed6-db30-47af-a249-21e2882ce310",
      "metadata": {
        "id": "7edaeed6-db30-47af-a249-21e2882ce310",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "114f30c0-b4cd-4f83-d595-58c505f136bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.06797595\n"
          ]
        }
      ],
      "source": [
        "print(model.wv.similarity('it', 'this'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ceecc74-18a7-4174-bd94-b6114bb05da4",
      "metadata": {
        "id": "5ceecc74-18a7-4174-bd94-b6114bb05da4"
      },
      "source": [
        "On the other hand these 2 words should produce a smaller similarity (a number close to zero). Negative number would indicate opposite meaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "dde3f1ba-d732-46de-8645-b08acf59a802",
      "metadata": {
        "id": "dde3f1ba-d732-46de-8645-b08acf59a802",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9deb09dc-b944-445d-9ca6-45f9096d2c79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.016134685\n"
          ]
        }
      ],
      "source": [
        "print(model.wv.similarity('one', 'makes'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2360a2ed-2011-4eed-b7a0-247b23784694",
      "metadata": {
        "id": "2360a2ed-2011-4eed-b7a0-247b23784694"
      },
      "source": [
        "## How to explore further"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bc8ab33-d7b3-44d7-b487-130cbf4b5dc5",
      "metadata": {
        "id": "5bc8ab33-d7b3-44d7-b487-130cbf4b5dc5"
      },
      "source": [
        "Try adding your own sentences, loading them into model and calculating the similarity between specific words. Do your results make sense?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "184025df-5086-4e7f-8e96-9d322fe8c31a",
      "metadata": {
        "id": "184025df-5086-4e7f-8e96-9d322fe8c31a"
      },
      "source": [
        "### End of Lab 2"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}